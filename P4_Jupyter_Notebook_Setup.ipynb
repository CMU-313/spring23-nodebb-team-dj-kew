{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1x0IhqJG6RDu9RIzsU8ZqHH775vJQs2kS",
      "authorship_tag": "ABX9TyO6Zs/BbYHaVm7ft6FB/P0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CMU-313/spring23-nodebb-team-dj-kew/blob/K%2Fjupyter-notebook-setup/P4_Jupyter_Notebook_Setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to copy the following files from https://github.com/CMU-313/NodeBB/pull/186/files\n",
        "\n",
        "- `career-model/requirements.txt`\n",
        "- `career-model/model.pkl`"
      ],
      "metadata": {
        "id": "etFvZUgTrPoS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AmDp_nEk0B0",
        "outputId": "433b09e0-f681-418b-a64b-595b40474919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.16\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: joblib==1.2.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: numpy==1.24.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 2)) (1.24.2)\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 3)) (1.5.3)\n",
            "Requirement already satisfied: pydantic==1.10.6 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 4)) (1.10.6)\n",
            "Requirement already satisfied: python-dateutil==2.8.2 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz==2022.7.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 6)) (2022.7.1)\n",
            "Requirement already satisfied: scikit-learn==1.2.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 7)) (1.2.1)\n",
            "Requirement already satisfied: scipy==1.10.1 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 8)) (1.10.1)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl==3.1.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 10)) (3.1.0)\n",
            "Requirement already satisfied: typing_extensions==4.5.0 in /usr/local/lib/python3.9/dist-packages (from -r requirements.txt (line 11)) (4.5.0)\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the model and test dataset"
      ],
      "metadata": {
        "id": "wZakORxzmEUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from pydantic import BaseModel, Field\n",
        "from pydantic.tools import parse_obj_as\n",
        "\n",
        "# Pydantic Models\n",
        "class Student(BaseModel):\n",
        "    student_id: str = Field(alias=\"Student ID\")\n",
        "    gender: str = Field(alias=\"Gender\")\n",
        "    age: str = Field(alias=\"Age\")\n",
        "    major: str = Field(alias=\"Major\")\n",
        "    gpa: str = Field(alias=\"GPA\")\n",
        "    extra_curricular: str = Field(alias=\"Extra Curricular\")\n",
        "    num_programming_languages: str = Field(alias=\"Num Programming Languages\")\n",
        "    num_past_internships: str = Field(alias=\"Num Past Internships\")\n",
        "\n",
        "    class Config:\n",
        "        allow_population_by_field_name = True\n",
        "\n",
        "class PredictionResult(BaseModel):\n",
        "    good_employee: int\n",
        "\n",
        "\n",
        "# Main Functionality\n",
        "def predict(student):\n",
        "    '''\n",
        "    Returns a prediction on whether the student will be a good employee\n",
        "    based on given parameters by using the ML model\n",
        "    Parameters\n",
        "    ----------\n",
        "    student : dict\n",
        "        A dictionary that contains all fields in Student\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    dict\n",
        "        A dictionary satisfying type PredictionResult, contains a single field\n",
        "        'good_employee' which is either 1 (will be a good employee) or 0 (will\n",
        "        not be a good employee)\n",
        "    '''\n",
        "    # Use Pydantic to validate model fields exist\n",
        "    student = parse_obj_as(Student, student)\n",
        "\n",
        "    clf = joblib.load('./model.pkl')\n",
        "\n",
        "    student = student.dict(by_alias=True)\n",
        "    query = pd.DataFrame(student, index=[0])\n",
        "    prediction = clf.predict(query) # TODO: Error handling ??\n",
        "\n",
        "    return { 'good_employee': prediction[0] }\n",
        "\n",
        "# Sample run\n",
        "student = {\n",
        "    \"student_id\": \"student1\",\n",
        "    \"major\": \"Computer Science\",\n",
        "    \"age\": \"20\",\n",
        "    \"gender\": \"M\",\n",
        "    \"gpa\": \"4.0\",\n",
        "    \"extra_curricular\": \"Men's Basketball\",\n",
        "    \"num_programming_languages\": \"0\",\n",
        "    \"num_past_internships\": \"0\"\n",
        "}\n",
        "predict(student)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2EfVVzBrMxD",
        "outputId": "6409cdaa-7543-4fe5-a0f0-a1e384221612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'good_employee': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the distribution of the test dataset across all features (except Student ID) using any visualization library of your choice (e.g. pandas, matplotlib, seaborn, plotly, etc.). You should choose the appropriate visualization for each feature."
      ],
      "metadata": {
        "id": "t4Yh-YlNnOd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('student_data.csv')\n",
        "df_good = df.loc[(df['Good Candidate'] == 1)]\n",
        "df_bad = df.loc[(df['Good Candidate'] == 0)]\n",
        "\n",
        "# Distribution of GPA, based on Good Candidate\n",
        "df.plot.hist(column=[\"GPA\"], by=\"Good Candidate\", figsize=(10, 8))\n",
        "\n",
        "# Distribution of every other field\n",
        "fields = ['Gender', 'Age', 'Major', 'Extra Curricular', 'Num Programming Languages', 'Num Past Internships']\n",
        "for field in fields:\n",
        "  fig, ax = plt.subplots()\n",
        "  df[field].value_counts().sort_index().plot(ax=ax, kind='bar', title=field)"
      ],
      "metadata": {
        "id": "_zdrdfeEnWrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the output of the test dataset using the model"
      ],
      "metadata": {
        "id": "rMjsXUugnPYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student = {\n",
        "    \"student_id\": \"student1\",\n",
        "    \"major\": \"Computer Science\",\n",
        "    \"age\": \"20\",\n",
        "    \"gender\": \"M\",\n",
        "    \"gpa\": \"4.0\",\n",
        "    \"extra_curricular\": \"Men's Basketball\",\n",
        "    \"num_programming_languages\": \"0\",\n",
        "    \"num_past_internships\": \"0\"\n",
        "}\n",
        "predict(student)\n",
        "\n",
        "# Keep track of outputs, predicted vs actual for accuracy metrics later\n",
        "predicted_outputs = []\n",
        "actual_outputs = []\n",
        "\n",
        "# Iterate over dataset and predict each student (THIS TAKES ABOUT 3 MINUTES)\n",
        "for index, row in df.iterrows():\n",
        "  fields = [\"student_id\", \"major\", \"age\", \"gender\", \"gpa\", \"extra_curricular\", \"num_programming_languages\", \"num_past_internships\"]\n",
        "  col_names = ['Student ID', 'Major', 'Age', 'Gender', 'GPA', 'Extra Curricular', 'Num Programming Languages', 'Num Past Internships']\n",
        "\n",
        "  # Construct a student object to be predicted\n",
        "  student = dict()\n",
        "  for i in range(len(fields)):\n",
        "    curr_field = fields[i]\n",
        "    curr_col = col_names[i]\n",
        "    student[curr_field] = row[curr_col]\n",
        "\n",
        "  # Get the outputs, predicted and actual\n",
        "  predicted_outputs.append(predict(student)['good_employee'])\n",
        "  actual_outputs.append(row['Good Candidate'])"
      ],
      "metadata": {
        "id": "y7ciYbmhnWJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Report the accuracy of the model, and the confusion matrix"
      ],
      "metadata": {
        "id": "B1_KIoAKnRDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "print(\"Accuracy score: \", accuracy_score(actual_outputs, predicted_outputs))\n",
        "print(\"Confusion matrix: \\n\", confusion_matrix(actual_outputs, predicted_outputs))"
      ],
      "metadata": {
        "id": "-0eVebufnTa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d9f650-9946-45c9-edba-78cfb7a7471f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:  0.832\n",
            "Confusion matrix: \n",
            " [[221  42]\n",
            " [ 42 195]]\n"
          ]
        }
      ]
    }
  ]
}